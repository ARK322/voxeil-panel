name: Integration Test (k3s)

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: read
  packages: read

jobs:
  integration:
    name: k3s Integration Test
    runs-on: ubuntu-22.04
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install k3s
        run: |
          curl -sfL https://get.k3s.io | sh -
          sudo mkdir -p /etc/rancher/k3s
          sudo chmod 644 /etc/rancher/k3s/k3s.yaml || true
          export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
          echo "KUBECONFIG=/etc/rancher/k3s/k3s.yaml" >> $GITHUB_ENV
          # Ensure k3s service is running
          sudo systemctl start k3s || true
          sudo systemctl enable k3s || true
          # Wait for k3s API to be ready
          timeout 120 bash -c 'until kubectl cluster-info &>/dev/null; do sleep 2; done' || exit 1
          kubectl cluster-info
          kubectl config get-contexts
          # Wait for node to be registered (k3s needs time to register the node)
          echo "Waiting for node to be registered..."
          for i in {1..90}; do
            if kubectl get nodes --no-headers 2>/dev/null | grep -q .; then
              echo "Node registered!"
              kubectl get nodes -o wide
              # Wait for node to be Ready
              kubectl wait node --all --for=condition=Ready --timeout=180s || exit 1
              echo "Node is Ready!"
              break
            fi
            if [ $i -eq 90 ]; then
              echo "ERROR: Node not registered after 180 seconds"
              kubectl get nodes
              sudo systemctl status k3s || true
              exit 1
            fi
            sleep 2
          done

      - name: Configure kubectl access
        run: |
          sudo chmod 644 /etc/rancher/k3s/k3s.yaml
          mkdir -p ~/.kube
          cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
          export KUBECONFIG=~/.kube/config
          echo "KUBECONFIG=~/.kube/config" >> $GITHUB_ENV
          kubectl cluster-info
          kubectl config get-contexts
          # Verify nodes exist and are Ready (should already be from Install k3s step, but verify)
          kubectl get nodes -o wide
          if ! kubectl get nodes --no-headers 2>/dev/null | grep -q .; then
            echo "ERROR: No nodes found after k3s installation"
            kubectl get nodes
            exit 1
          fi
          kubectl wait node --all --for=condition=Ready --timeout=60s || exit 1
          echo "All nodes are Ready"

      - name: Build and load application images into k3s
        run: |
          # Verify Docker is available (usually pre-installed on GitHub Actions runners)
          docker --version || { echo "ERROR: Docker not available"; exit 1; }
          
          # Build controller and panel images locally
          echo "Building voxeil-controller image..."
          docker build -f apps/controller/Dockerfile -t ghcr.io/ark322/voxeil-controller:latest .
          
          echo "Building voxeil-panel image..."
          docker build -f apps/panel/Dockerfile -t ghcr.io/ark322/voxeil-panel:latest .
          
          # Import images into k3s containerd
          # Save images to temporary files and import via k3s ctr
          echo "Importing controller image into k3s..."
          docker save ghcr.io/ark322/voxeil-controller:latest -o /tmp/controller.tar
          sudo k3s ctr images import /tmp/controller.tar || {
            echo "Warning: Failed to import via ctr, trying direct load..."
            # Alternative: use k3s's image import capability
            sudo k3s ctr -n k8s.io images import /tmp/controller.tar || true
          }
          rm -f /tmp/controller.tar
          
          echo "Importing panel image into k3s..."
          docker save ghcr.io/ark322/voxeil-panel:latest -o /tmp/panel.tar
          sudo k3s ctr images import /tmp/panel.tar || {
            echo "Warning: Failed to import via ctr, trying direct load..."
            sudo k3s ctr -n k8s.io images import /tmp/panel.tar || true
          }
          rm -f /tmp/panel.tar
          
          # Verify images are available (may not show up immediately, but will be available when referenced)
          echo "Checking imported images..."
          sudo k3s ctr images ls 2>/dev/null | grep -E "(voxeil-controller|voxeil-panel)" || echo "Note: Images imported, will be available when pods reference them"

      - name: Make scripts executable (safe)
        run: |
          # Make voxeil.sh executable (main entrypoint)
          chmod +x voxeil.sh || true
          # Make any existing scripts executable (safe - won't fail if directories don't exist)
          find cmd phases lib tools -name "*.sh" -type f -exec chmod +x {} \; 2>/dev/null || true

      - name: First install
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh install --skip-k3s

      - name: Collect logs after first install
        if: failure()
        run: |
          export KUBECONFIG=~/.kube/config
          echo "=== Pods Status ==="
          kubectl get pods -A || true
          echo ""
          echo "=== Recent Events ==="
          kubectl get events -A --sort-by=.metadata.creationTimestamp | tail -n 200 || true
          echo ""
          echo "=== Pod Descriptions ==="
          kubectl describe pods -A | tail -n 200 || true

      - name: First doctor check
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh doctor

      - name: Uninstall
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh uninstall --force

      - name: Collect logs after uninstall
        if: failure()
        run: |
          export KUBECONFIG=~/.kube/config
          echo "=== Pods Status ==="
          kubectl get pods -A || true
          echo ""
          echo "=== Recent Events ==="
          kubectl get events -A --sort-by=.metadata.creationTimestamp | tail -n 200 || true
          echo ""
          echo "=== Pod Descriptions ==="
          kubectl describe pods -A | tail -n 200 || true

      - name: Second install
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh install --skip-k3s

      - name: Collect logs after second install
        if: failure()
        run: |
          export KUBECONFIG=~/.kube/config
          echo "=== Pods Status ==="
          kubectl get pods -A || true
          echo ""
          echo "=== Recent Events ==="
          kubectl get events -A --sort-by=.metadata.creationTimestamp | tail -n 200 || true
          echo ""
          echo "=== Pod Descriptions ==="
          kubectl describe pods -A | tail -n 200 || true

      - name: Final doctor check
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh doctor

      - name: Cleanup (collect final state)
        if: always()
        run: |
          export KUBECONFIG=~/.kube/config
          echo "=== Final Pods Status ==="
          kubectl get pods -A || true
          echo ""
          echo "=== Final Namespaces ==="
          kubectl get namespaces || true

