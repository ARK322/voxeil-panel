name: Integration Test (k3s)

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: read
  packages: read

jobs:
  integration:
    name: k3s Integration Test
    runs-on: ubuntu-22.04
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install k3s
        run: |
          curl -sfL https://get.k3s.io | sh -
          sudo mkdir -p /etc/rancher/k3s
          sudo chmod 644 /etc/rancher/k3s/k3s.yaml || true
          export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
          echo "KUBECONFIG=/etc/rancher/k3s/k3s.yaml" >> $GITHUB_ENV
          # Ensure k3s service is running
          sudo systemctl start k3s || true
          sudo systemctl enable k3s || true
          # Wait for k3s API to be ready
          timeout 120 bash -c 'until kubectl cluster-info &>/dev/null; do sleep 2; done' || exit 1
          kubectl cluster-info
          kubectl config get-contexts
          # Wait for node to be registered (k3s needs time to register the node)
          echo "Waiting for node to be registered..."
          for i in {1..90}; do
            if kubectl get nodes --no-headers 2>/dev/null | grep -q .; then
              echo "Node registered!"
              kubectl get nodes -o wide
              # Wait for node to be Ready
              kubectl wait node --all --for=condition=Ready --timeout=180s || exit 1
              echo "Node is Ready!"
              break
            fi
            if [ $i -eq 90 ]; then
              echo "ERROR: Node not registered after 180 seconds"
              kubectl get nodes
              sudo systemctl status k3s || true
              exit 1
            fi
            sleep 2
          done

      - name: Configure kubectl access
        run: |
          sudo chmod 644 /etc/rancher/k3s/k3s.yaml
          mkdir -p ~/.kube
          cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
          export KUBECONFIG=~/.kube/config
          echo "KUBECONFIG=~/.kube/config" >> $GITHUB_ENV
          kubectl cluster-info
          kubectl config get-contexts
          # Verify nodes exist and are Ready (should already be from Install k3s step, but verify)
          kubectl get nodes -o wide
          if ! kubectl get nodes --no-headers 2>/dev/null | grep -q .; then
            echo "ERROR: No nodes found after k3s installation"
            kubectl get nodes
            exit 1
          fi
          kubectl wait node --all --for=condition=Ready --timeout=60s || exit 1
          echo "All nodes are Ready"

      - name: Set image variables
        run: |
          OWNER_LC=$(echo "$GITHUB_REPOSITORY_OWNER" | tr '[:upper:]' '[:lower:]')
          IMAGE_SHA_TAG="sha-${GITHUB_SHA}"
          echo "OWNER_LC=${OWNER_LC}" >> $GITHUB_ENV
          echo "IMAGE_SHA_TAG=${IMAGE_SHA_TAG}" >> $GITHUB_ENV
          echo "CONTROLLER_IMAGE=ghcr.io/${OWNER_LC}/voxeil-controller:${IMAGE_SHA_TAG}" >> $GITHUB_ENV
          echo "PANEL_IMAGE=ghcr.io/${OWNER_LC}/voxeil-panel:${IMAGE_SHA_TAG}" >> $GITHUB_ENV
          echo "Controller image: $CONTROLLER_IMAGE"
          echo "Panel image: $PANEL_IMAGE"

      - name: Pull and import base images into k3s
        run: |
          # Verify Docker is available
          docker --version || { echo "ERROR: Docker not available"; exit 1; }
          
          # List of base images required by infrastructure components
          BASE_IMAGES=(
            "alpine:3.19"
            "postgres:16-alpine"
            "dpage/pgadmin4:8.11"
          )
          
          echo "Pulling and importing base images into k3s..."
          for img in "${BASE_IMAGES[@]}"; do
            echo "Processing ${img}..."
            # Pull image
            docker pull "${img}" || {
              echo "WARNING: Failed to pull ${img}, continuing..."
              continue
            }
            
            # Save and import into k3s
            IMG_TAR="/tmp/$(echo ${img} | tr '/:' '_').tar"
            docker save "${img}" -o "${IMG_TAR}"
            if ! sudo k3s ctr images import "${IMG_TAR}" 2>&1; then
              echo "Trying alternative import method for ${img}..."
              sudo k3s ctr -n k8s.io images import "${IMG_TAR}" 2>&1 || {
                echo "WARNING: Failed to import ${img}, continuing..."
                rm -f "${IMG_TAR}"
                continue
              }
            fi
            rm -f "${IMG_TAR}"
            echo "  ✓ Imported ${img}"
          done
          
          echo "Base images import complete"

      - name: Build and load application images into k3s
        run: |
          # Verify Docker is available (usually pre-installed on GitHub Actions runners)
          docker --version || { echo "ERROR: Docker not available"; exit 1; }
          
          # Build controller and panel images locally with SHA tags
          echo "Building voxeil-controller image..."
          docker build -f apps/controller/Dockerfile -t ${CONTROLLER_IMAGE} -t ghcr.io/${OWNER_LC}/voxeil-controller:latest .
          
          echo "Building voxeil-panel image..."
          docker build -f apps/panel/Dockerfile -t ${PANEL_IMAGE} -t ghcr.io/${OWNER_LC}/voxeil-panel:latest .
          
          # Import images into k3s containerd using SHA tag (primary)
          echo "Importing controller image into k3s (${CONTROLLER_IMAGE})..."
          docker save ${CONTROLLER_IMAGE} -o /tmp/controller.tar
          if ! sudo k3s ctr images import /tmp/controller.tar 2>&1; then
            echo "Trying alternative import method..."
            sudo k3s ctr -n k8s.io images import /tmp/controller.tar 2>&1 || {
              echo "ERROR: Failed to import controller image"
              exit 1
            }
          fi
          rm -f /tmp/controller.tar
          
          echo "Importing panel image into k3s (${PANEL_IMAGE})..."
          docker save ${PANEL_IMAGE} -o /tmp/panel.tar
          if ! sudo k3s ctr images import /tmp/panel.tar 2>&1; then
            echo "Trying alternative import method..."
            sudo k3s ctr -n k8s.io images import /tmp/panel.tar 2>&1 || {
              echo "ERROR: Failed to import panel image"
              exit 1
            }
          fi
          rm -f /tmp/panel.tar
          
          # Verify images are available
          echo "Checking imported images..."
          sudo k3s ctr images ls 2>/dev/null | grep -E "(voxeil-controller|voxeil-panel|alpine|postgres|pgadmin)" || echo "Note: Images imported, will be available when pods reference them"
          
          # Set environment variable for installer to use SHA tags
          echo "VOXEIL_CI=1" >> $GITHUB_ENV
          echo "VOXEIL_CONTROLLER_IMAGE=${CONTROLLER_IMAGE}" >> $GITHUB_ENV
          echo "VOXEIL_PANEL_IMAGE=${PANEL_IMAGE}" >> $GITHUB_ENV

      - name: Make scripts executable (safe)
        run: |
          # Make voxeil.sh executable (main entrypoint)
          chmod +x voxeil.sh || true
          # Make any existing scripts executable (safe - won't fail if directories don't exist)
          find cmd phases lib tools -name "*.sh" -type f -exec chmod +x {} \; 2>/dev/null || true

      - name: First install
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh install --skip-k3s

      - name: Collect debug artifacts on failure
        if: failure()
        run: |
          export KUBECONFIG=~/.kube/config
          mkdir -p debug-artifacts
          echo "==========================================" > debug-artifacts/debug-bundle.txt
          echo "DEBUG BUNDLE START" >> debug-artifacts/debug-bundle.txt
          echo "==========================================" >> debug-artifacts/debug-bundle.txt
          echo "" >> debug-artifacts/debug-bundle.txt
          echo "=== All Pods Status ===" >> debug-artifacts/debug-bundle.txt
          kubectl get pods -A -o wide >> debug-artifacts/debug-bundle.txt 2>&1 || true
          echo "" >> debug-artifacts/debug-bundle.txt
          echo "=== Recent Events (sorted by timestamp) ===" >> debug-artifacts/debug-bundle.txt
          kubectl get events -A --sort-by='.lastTimestamp' | tail -n 200 >> debug-artifacts/debug-bundle.txt 2>&1 || true
          echo "" >> debug-artifacts/debug-bundle.txt
          echo "=== Controller Deployment ===" >> debug-artifacts/debug-bundle.txt
          kubectl describe deployment controller -n platform >> debug-artifacts/debug-bundle.txt 2>&1 || true
          echo "" >> debug-artifacts/debug-bundle.txt
          echo "=== Panel Deployment ===" >> debug-artifacts/debug-bundle.txt
          kubectl describe deployment panel -n platform >> debug-artifacts/debug-bundle.txt 2>&1 || true
          echo "" >> debug-artifacts/debug-bundle.txt
          echo "=== Controller Pods ===" >> debug-artifacts/debug-bundle.txt
          kubectl get pods -n platform -l app=controller -o wide >> debug-artifacts/debug-bundle.txt 2>&1 || true
          for pod in $(kubectl get pods -n platform -l app=controller -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo ""); do
            if [ -n "${pod}" ]; then
              echo "--- Logs: ${pod} ---" >> debug-artifacts/debug-bundle.txt
              kubectl logs "${pod}" -n platform --tail=200 >> debug-artifacts/debug-bundle.txt 2>&1 || true
            fi
          done
          echo "" >> debug-artifacts/debug-bundle.txt
          echo "=== Panel Pods ===" >> debug-artifacts/debug-bundle.txt
          kubectl get pods -n platform -l app=panel -o wide >> debug-artifacts/debug-bundle.txt 2>&1 || true
          for pod in $(kubectl get pods -n platform -l app=panel -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo ""); do
            if [ -n "${pod}" ]; then
              echo "--- Logs: ${pod} ---" >> debug-artifacts/debug-bundle.txt
              kubectl logs "${pod}" -n platform --tail=200 >> debug-artifacts/debug-bundle.txt 2>&1 || true
            fi
          done
          echo "" >> debug-artifacts/debug-bundle.txt
          echo "==========================================" >> debug-artifacts/debug-bundle.txt
          echo "DEBUG BUNDLE END" >> debug-artifacts/debug-bundle.txt
          echo "==========================================" >> debug-artifacts/debug-bundle.txt
          
      - name: Upload debug artifacts
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: debug-bundle
          path: debug-artifacts/
          retention-days: 7

      - name: First doctor check
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh doctor

      - name: Uninstall
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh uninstall --force

      - name: Collect logs after uninstall
        if: failure()
        run: |
          export KUBECONFIG=~/.kube/config
          echo "=== Pods Status ==="
          kubectl get pods -A || true
          echo ""
          echo "=== Recent Events ==="
          kubectl get events -A --sort-by=.metadata.creationTimestamp | tail -n 200 || true
          echo ""
          echo "=== Pod Descriptions ==="
          kubectl describe pods -A | tail -n 200 || true

      - name: Second install
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh install --skip-k3s

      - name: Collect debug artifacts after second install
        if: failure()
        run: |
          export KUBECONFIG=~/.kube/config
          mkdir -p debug-artifacts
          echo "==========================================" > debug-artifacts/debug-bundle-second-install.txt
          echo "DEBUG BUNDLE START" >> debug-artifacts/debug-bundle-second-install.txt
          echo "==========================================" >> debug-artifacts/debug-bundle-second-install.txt
          kubectl get pods -A -o wide >> debug-artifacts/debug-bundle-second-install.txt 2>&1 || true
          kubectl get events -A --sort-by='.lastTimestamp' | tail -n 200 >> debug-artifacts/debug-bundle-second-install.txt 2>&1 || true
          echo "==========================================" >> debug-artifacts/debug-bundle-second-install.txt
          echo "DEBUG BUNDLE END" >> debug-artifacts/debug-bundle-second-install.txt
          echo "==========================================" >> debug-artifacts/debug-bundle-second-install.txt

      - name: Final doctor check
        run: |
          export KUBECONFIG=~/.kube/config
          bash voxeil.sh doctor

      - name: Cleanup (collect final state)
        if: always()
        run: |
          export KUBECONFIG=~/.kube/config
          echo "=== Final Pods Status ==="
          kubectl get pods -A || true
          echo ""
          echo "=== Final Namespaces ==="
          kubectl get namespaces || true

